"""
data_processing.py
Paso 1 del Pipeline MLOps: Carga y limpieza de datos

Este script carga los datos crudos desde el CSV, realiza limpieza bÃ¡sica
y guarda el dataset limpio para el siguiente paso del pipeline.
"""

import pandas as pd
import numpy as np
import json
import os
from pathlib import Path


def load_config():
    """Carga la configuraciÃ³n del proyecto desde config.json"""
    config_path = Path(__file__).parent.parent.parent / "config.json"
    
    if config_path.exists():
        with open(config_path, 'r') as f:
            return json.load(f)
    else:
        return {
            "data_path": "alzheimers_disease_data.csv",
            "training": {"test_size": 0.2, "random_state": 42}
        }


def load_raw_data(config):
    """Carga el dataset crudo desde CSV"""
    project_root = Path(__file__).parent.parent.parent
    data_path = project_root / config.get('data_path', 'alzheimers_disease_data.csv')
    
    if not data_path.exists():
        raise FileNotFoundError(f"No se encontrÃ³ el archivo de datos: {data_path}")
    
    print(f"âœ“ Cargando datos desde: {data_path}")
    df = pd.read_csv(data_path)
    print(f"  Dimensiones: {df.shape[0]} filas Ã— {df.shape[1]} columnas")
    
    return df


def clean_data(df):
    """
    Realiza limpieza bÃ¡sica del dataset:
    - Elimina duplicados
    - Maneja valores faltantes
    - Corrige tipos de datos
    - Elimina columnas innecesarias para el modelo
    """
    print("\n" + "="*80)
    print("LIMPIEZA DE DATOS")
    print("="*80)
    
    # Crear copia para no modificar el original
    df_clean = df.copy()
    
    # 1. Eliminar duplicados
    n_duplicates = df_clean.duplicated().sum()
    if n_duplicates > 0:
        df_clean = df_clean.drop_duplicates()
        print(f"âœ“ Eliminados {n_duplicates} registros duplicados")
    else:
        print("âœ“ No se encontraron duplicados")
    
    # 2. InformaciÃ³n sobre valores faltantes
    missing_info = df_clean.isnull().sum()
    if missing_info.sum() > 0:
        print(f"\nðŸ“Š Valores faltantes detectados:")
        for col, count in missing_info[missing_info > 0].items():
            pct = (count / len(df_clean)) * 100
            print(f"   {col}: {count} ({pct:.2f}%)")
        print(f"   (Se manejarÃ¡n en la etapa de feature engineering)")
    else:
        print("\nâœ“ No hay valores faltantes")
    
    # 3. Verificar y corregir tipos de datos
    print(f"\nðŸ“‹ Tipos de datos:")
    numeric_cols = df_clean.select_dtypes(include=['int64', 'float64']).columns.tolist()
    categorical_cols = df_clean.select_dtypes(include=['object']).columns.tolist()
    print(f"   NumÃ©ricas: {len(numeric_cols)} columnas")
    print(f"   CategÃ³ricas: {len(categorical_cols)} columnas")
    
    # 4. Eliminar columnas de identificaciÃ³n que no son features
    # (PatientID y DoctorInCharge son identificadores, no features)
    # Nota: Diagnosis es el target y se mantiene
    id_columns = ['PatientID', 'DoctorInCharge']
    existing_id_cols = [col for col in id_columns if col in df_clean.columns]
    
    if existing_id_cols:
        df_clean = df_clean.drop(columns=existing_id_cols)
        print(f"\nâœ“ Eliminadas columnas de identificaciÃ³n: {existing_id_cols}")
    
    print(f"\nâœ… Limpieza completada")
    print(f"   Dimensiones finales: {df_clean.shape[0]} filas Ã— {df_clean.shape[1]} columnas")
    
    return df_clean


def save_cleaned_data(df, output_path):
    """Guarda el dataset limpio en el directorio de datos procesados"""
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    df.to_csv(output_path, index=False)
    print(f"\nðŸ’¾ Dataset limpio guardado en: {output_path}")


def main():
    """FunciÃ³n principal del script de procesamiento de datos"""
    print("="*80)
    print("PASO 1: PROCESAMIENTO DE DATOS")
    print("="*80)
    
    # 1. Cargar configuraciÃ³n
    config = load_config()
    
    # 2. Cargar datos crudos
    df_raw = load_raw_data(config)
    
    # 3. Limpiar datos
    df_clean = clean_data(df_raw)
    
    # 4. Guardar datos limpios
    project_root = Path(__file__).parent.parent.parent
    output_path = project_root / "data" / "processed" / "cleaned_data.csv"
    save_cleaned_data(df_clean, output_path)
    
    print("\n" + "="*80)
    print("âœ… PASO 1 COMPLETADO EXITOSAMENTE")
    print("="*80)
    print(f"\nSiguiente paso: Ejecutar ft_engineering.py")


if __name__ == "__main__":
    main()
