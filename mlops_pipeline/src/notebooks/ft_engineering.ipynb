{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4887eb4",
   "metadata": {},
   "source": [
    "# Feature Engineering - Pipeline MLOps\n",
    "\n",
    "Este notebook implementa la **Ingenier√≠a de Caracter√≠sticas** para el proyecto de predicci√≥n de Alzheimer.\n",
    "\n",
    "**üîç Prop√≥sito de este Notebook:**\n",
    "- Este notebook es **AUTOCONTENIDO** y puede ejecutarse de forma independiente\n",
    "- Muestra de forma manual y gr√°fica el proceso de Feature Engineering\n",
    "- No depende de scripts externos ni de pasos anteriores\n",
    "- Ideal para revisi√≥n, comprensi√≥n y experimentaci√≥n\n",
    "\n",
    "**Funcionalidades:**\n",
    "- Carga de datos directamente desde el CSV original\n",
    "- Limpieza b√°sica de datos (eliminar IDs, duplicados)\n",
    "- Creaci√≥n de features derivados basados en el an√°lisis EDA\n",
    "- Clasificaci√≥n autom√°tica de tipos de variables\n",
    "- Construcci√≥n de pipelines de preprocesamiento (sklearn)\n",
    "- Transformaciones: imputaci√≥n, escalado, codificaci√≥n\n",
    "- Separaci√≥n train-test estratificada\n",
    "- Visualizaciones del proceso de transformaci√≥n\n",
    "- Guardado de artefactos (preprocessor, datasets transformados)\n",
    "\n",
    "**üìã Diferencia con los Scripts:**\n",
    "- **Notebooks (`/notebooks/`)**: Revisi√≥n manual paso a paso, con visualizaciones y explicaciones\n",
    "- **Scripts (`/scripts/`)**: Automatizaci√≥n para ejecuci√≥n completa del pipeline y Docker\n",
    "\n",
    "**Basado en hallazgos del EDA:** `comprension_eda.ipynb` (Secci√≥n 8.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c10d0412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Librer√≠as importadas correctamente\n",
      "‚úì Pandas versi√≥n: 1.5.3\n",
      "‚úì Numpy versi√≥n: 1.24.3\n"
     ]
    }
   ],
   "source": [
    "# Importar librer√≠as necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Sklearn para feature engineering\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Configuraci√≥n visual\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úì Librer√≠as importadas correctamente\")\n",
    "print(f\"‚úì Pandas versi√≥n: {pd.__version__}\")\n",
    "print(f\"‚úì Numpy versi√≥n: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3862c29f",
   "metadata": {},
   "source": [
    "## 1. Cargar Datos Originales y Configuraci√≥n\n",
    "\n",
    "Cargamos el dataset original directamente desde el CSV y la configuraci√≥n del proyecto.\n",
    "\n",
    "**Nota:** Este notebook NO depende de pasos anteriores. Carga los datos originales y realiza toda la limpieza necesaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68dec5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Configuraci√≥n cargada desde config.json\n",
      "\n",
      "üìä Par√°metros de configuraci√≥n:\n",
      "   ‚Ä¢ Test size: 0.2\n",
      "   ‚Ä¢ Random state: 42\n"
     ]
    }
   ],
   "source": [
    "# Cargar configuraci√≥n\n",
    "config_path = \"../../../config.json\"\n",
    "\n",
    "if os.path.exists(config_path):\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    print(\"‚úì Configuraci√≥n cargada desde config.json\")\n",
    "else:\n",
    "    config = {\"training\": {\"test_size\": 0.2, \"random_state\": 42}}\n",
    "    print(\"‚ö†Ô∏è config.json no encontrado. Usando configuraci√≥n por defecto\")\n",
    "\n",
    "# Extraer par√°metros de entrenamiento\n",
    "test_size = config.get('training', {}).get('test_size', 0.2)\n",
    "random_state = config.get('training', {}).get('random_state', 42)\n",
    "\n",
    "print(f\"\\nüìä Par√°metros de configuraci√≥n:\")\n",
    "print(f\"   ‚Ä¢ Test size: {test_size}\")\n",
    "print(f\"   ‚Ä¢ Random state: {random_state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18280f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Dataset ORIGINAL cargado desde: ../../../alzheimers_disease_data.csv\n",
      "  Dimensiones: 2149 filas √ó 35 columnas\n",
      "\n",
      "üìã Primeras filas del dataset ORIGINAL:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PatientID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Gender",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Ethnicity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EducationLevel",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "BMI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Smoking",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "AlcoholConsumption",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PhysicalActivity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DietQuality",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SleepQuality",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "FamilyHistoryAlzheimers",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "CardiovascularDisease",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Diabetes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Depression",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "HeadInjury",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Hypertension",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "SystolicBP",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "DiastolicBP",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "CholesterolTotal",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CholesterolLDL",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CholesterolHDL",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CholesterolTriglycerides",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "FunctionalAssessment",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MemoryComplaints",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "BehavioralProblems",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ADL",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Confusion",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Disorientation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PersonalityChanges",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "DifficultyCompletingTasks",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Forgetfulness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Diagnosis",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "DoctorInCharge",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "e1bb0629-c00e-439c-bf6e-f759e7d8fa1e",
       "rows": [
        [
         "0",
         "4751",
         "73",
         "0",
         "0",
         "2",
         "22.927749230993864",
         "0",
         "13.29721772827684",
         "6.327112473553353",
         "1.3472143059081076",
         "9.025678665766115",
         "0",
         "0",
         "1",
         "1",
         "0",
         "0",
         "142",
         "72",
         "242.3668396963656",
         "56.15089696091113",
         "33.68256349839592",
         "162.18914307736603",
         "21.46353236431666",
         "6.518876973217633",
         "0",
         "0",
         "1.7258834599441897",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "XXXConfid"
        ],
        [
         "1",
         "4752",
         "89",
         "0",
         "0",
         "0",
         "26.82768119159602",
         "0",
         "4.542523817722191",
         "7.619884540163032",
         "0.5187671386507053",
         "7.151292743051223",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "115",
         "64",
         "231.16259501016503",
         "193.4079955157258",
         "79.02847731570753",
         "294.63090921495643",
         "20.61326730888292",
         "7.118695504189474",
         "0",
         "0",
         "2.5924241326736475",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "XXXConfid"
        ],
        [
         "2",
         "4753",
         "73",
         "0",
         "3",
         "1",
         "17.795882442817113",
         "0",
         "19.55508452555359",
         "7.844987790974517",
         "1.826334664579784",
         "9.673574157961111",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "99",
         "116",
         "284.1818577646338",
         "153.3227621844376",
         "69.77229186479597",
         "83.63832413899468",
         "7.356248624670334",
         "5.895077345354194",
         "0",
         "0",
         "7.119547742738579",
         "0",
         "1",
         "0",
         "1",
         "0",
         "0",
         "XXXConfid"
        ],
        [
         "3",
         "4754",
         "74",
         "1",
         "0",
         "1",
         "33.80081704413547",
         "1",
         "12.209265546203785",
         "8.428001350491492",
         "7.43560414000302",
         "8.392553685350862",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "118",
         "115",
         "159.58223960561193",
         "65.36663683521382",
         "68.45749070794797",
         "277.5773575001914",
         "13.991127243891668",
         "8.965106303658107",
         "0",
         "1",
         "6.48122585936608",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "XXXConfid"
        ],
        [
         "4",
         "4755",
         "89",
         "0",
         "0",
         "0",
         "20.716973826446807",
         "0",
         "18.45435609061961",
         "6.310460689360432",
         "0.7954975089177474",
         "5.597237677578526",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "94",
         "117",
         "237.6021836280377",
         "92.8696998816807",
         "56.87430466708379",
         "291.1987801806695",
         "13.517608895586092",
         "6.045038774287464",
         "0",
         "0",
         "0.014691221285652",
         "0",
         "0",
         "1",
         "1",
         "0",
         "0",
         "XXXConfid"
        ]
       ],
       "shape": {
        "columns": 35,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AlcoholConsumption</th>\n",
       "      <th>PhysicalActivity</th>\n",
       "      <th>DietQuality</th>\n",
       "      <th>...</th>\n",
       "      <th>MemoryComplaints</th>\n",
       "      <th>BehavioralProblems</th>\n",
       "      <th>ADL</th>\n",
       "      <th>Confusion</th>\n",
       "      <th>Disorientation</th>\n",
       "      <th>PersonalityChanges</th>\n",
       "      <th>DifficultyCompletingTasks</th>\n",
       "      <th>Forgetfulness</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>DoctorInCharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4751</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22.927749</td>\n",
       "      <td>0</td>\n",
       "      <td>13.297218</td>\n",
       "      <td>6.327112</td>\n",
       "      <td>1.347214</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.725883</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXConfid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4752</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.827681</td>\n",
       "      <td>0</td>\n",
       "      <td>4.542524</td>\n",
       "      <td>7.619885</td>\n",
       "      <td>0.518767</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.592424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXConfid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4753</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>17.795882</td>\n",
       "      <td>0</td>\n",
       "      <td>19.555085</td>\n",
       "      <td>7.844988</td>\n",
       "      <td>1.826335</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.119548</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXConfid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4754</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.800817</td>\n",
       "      <td>1</td>\n",
       "      <td>12.209266</td>\n",
       "      <td>8.428001</td>\n",
       "      <td>7.435604</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.481226</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXConfid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4755</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.716974</td>\n",
       "      <td>0</td>\n",
       "      <td>18.454356</td>\n",
       "      <td>6.310461</td>\n",
       "      <td>0.795498</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXConfid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PatientID  Age  Gender  Ethnicity  EducationLevel        BMI  Smoking  \\\n",
       "0       4751   73       0          0               2  22.927749        0   \n",
       "1       4752   89       0          0               0  26.827681        0   \n",
       "2       4753   73       0          3               1  17.795882        0   \n",
       "3       4754   74       1          0               1  33.800817        1   \n",
       "4       4755   89       0          0               0  20.716974        0   \n",
       "\n",
       "   AlcoholConsumption  PhysicalActivity  DietQuality  ...  MemoryComplaints  \\\n",
       "0           13.297218          6.327112     1.347214  ...                 0   \n",
       "1            4.542524          7.619885     0.518767  ...                 0   \n",
       "2           19.555085          7.844988     1.826335  ...                 0   \n",
       "3           12.209266          8.428001     7.435604  ...                 0   \n",
       "4           18.454356          6.310461     0.795498  ...                 0   \n",
       "\n",
       "   BehavioralProblems       ADL  Confusion  Disorientation  \\\n",
       "0                   0  1.725883          0               0   \n",
       "1                   0  2.592424          0               0   \n",
       "2                   0  7.119548          0               1   \n",
       "3                   1  6.481226          0               0   \n",
       "4                   0  0.014691          0               0   \n",
       "\n",
       "   PersonalityChanges  DifficultyCompletingTasks  Forgetfulness  Diagnosis  \\\n",
       "0                   0                          1              0          0   \n",
       "1                   0                          0              1          0   \n",
       "2                   0                          1              0          0   \n",
       "3                   0                          0              0          0   \n",
       "4                   1                          1              0          0   \n",
       "\n",
       "   DoctorInCharge  \n",
       "0       XXXConfid  \n",
       "1       XXXConfid  \n",
       "2       XXXConfid  \n",
       "3       XXXConfid  \n",
       "4       XXXConfid  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cargar dataset ORIGINAL (no procesado)\n",
    "# Buscar primero desde config.json, sino usar el path por defecto\n",
    "\n",
    "data_path = None\n",
    "\n",
    "# Intentar cargar desde config\n",
    "if os.path.exists(config_path):\n",
    "    data_path = config.get('data_path_notebooks', \"../../../alzheimers_disease_data.csv\")\n",
    "else:\n",
    "    data_path = \"../../../alzheimers_disease_data.csv\"\n",
    "\n",
    "# Cargar dataset original\n",
    "if not os.path.exists(data_path):\n",
    "    print(\"‚ùå ERROR: No se encontr√≥ el archivo de datos\")\n",
    "    print(f\"   Buscado en: {data_path}\")\n",
    "    print(\"   Por favor, verifica que el archivo CSV existe en la ruta correcta\")\n",
    "else:\n",
    "    df_raw = pd.read_csv(data_path)\n",
    "    print(f\"‚úì Dataset ORIGINAL cargado desde: {data_path}\")\n",
    "    print(f\"  Dimensiones: {df_raw.shape[0]} filas √ó {df_raw.shape[1]} columnas\")\n",
    "    print(f\"\\nüìã Primeras filas del dataset ORIGINAL:\")\n",
    "    display(df_raw.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7a647b",
   "metadata": {},
   "source": [
    "## 1.5 Limpieza B√°sica de Datos\n",
    "\n",
    "Realizamos limpieza b√°sica antes del feature engineering:\n",
    "- Eliminar columnas de identificaci√≥n (PatientID, DoctorInCharge)\n",
    "- Eliminar duplicados\n",
    "- Verificar tipos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58c9dd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LIMPIEZA B√ÅSICA DE DATOS\n",
      "================================================================================\n",
      "\n",
      "üìä Dataset original: 2149 filas √ó 35 columnas\n",
      "‚úì No se encontraron duplicados\n",
      "‚úì Eliminadas columnas de identificaci√≥n: ['PatientID', 'DoctorInCharge']\n",
      "\n",
      "‚úì No hay valores faltantes\n",
      "\n",
      "üìã Tipos de datos:\n",
      "   Num√©ricas: 33 columnas\n",
      "   Categ√≥ricas: 0 columnas\n",
      "\n",
      "‚úÖ Limpieza completada\n",
      "   Dimensiones finales: 2149 filas √ó 33 columnas\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"LIMPIEZA B√ÅSICA DE DATOS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Crear copia para no modificar el original\n",
    "df = df_raw.copy()\n",
    "\n",
    "print(f\"üìä Dataset original: {df.shape[0]} filas √ó {df.shape[1]} columnas\")\n",
    "\n",
    "# 1. Eliminar duplicados\n",
    "n_duplicates = df.duplicated().sum()\n",
    "if n_duplicates > 0:\n",
    "    df = df.drop_duplicates()\n",
    "    print(f\"‚úì Eliminados {n_duplicates} registros duplicados\")\n",
    "else:\n",
    "    print(\"‚úì No se encontraron duplicados\")\n",
    "\n",
    "# 2. Eliminar columnas de identificaci√≥n (no son features predictivos)\n",
    "id_columns = ['PatientID', 'DoctorInCharge']\n",
    "existing_id_cols = [col for col in id_columns if col in df.columns]\n",
    "\n",
    "if existing_id_cols:\n",
    "    df = df.drop(columns=existing_id_cols)\n",
    "    print(f\"‚úì Eliminadas columnas de identificaci√≥n: {existing_id_cols}\")\n",
    "\n",
    "# 3. Informaci√≥n sobre valores faltantes (se manejar√°n en el pipeline)\n",
    "missing_info = df.isnull().sum()\n",
    "if missing_info.sum() > 0:\n",
    "    print(f\"\\nüìä Valores faltantes detectados (se imputar√°n en el pipeline):\")\n",
    "    for col, count in missing_info[missing_info > 0].items():\n",
    "        pct = (count / len(df)) * 100\n",
    "        print(f\"   {col}: {count} ({pct:.2f}%)\")\n",
    "else:\n",
    "    print(\"\\n‚úì No hay valores faltantes\")\n",
    "\n",
    "# 4. Verificar tipos de datos\n",
    "print(f\"\\nüìã Tipos de datos:\")\n",
    "numeric_cols_check = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols_check = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"   Num√©ricas: {len(numeric_cols_check)} columnas\")\n",
    "print(f\"   Categ√≥ricas: {len(categorical_cols_check)} columnas\")\n",
    "\n",
    "print(f\"\\n‚úÖ Limpieza completada\")\n",
    "print(f\"   Dimensiones finales: {df.shape[0]} filas √ó {df.shape[1]} columnas\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33578d35",
   "metadata": {},
   "source": [
    "## 2. Creaci√≥n de Features Derivados\n",
    "\n",
    "Basado en el an√°lisis EDA (`comprension_eda.ipynb` Secci√≥n 8.7), implementamos los features derivados m√°s relevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b105f5f",
   "metadata": {},
   "source": [
    "## 2.1 Justificaci√≥n Te√≥rica de Features Derivados\n",
    "\n",
    "Basado en literatura m√©dica y hallazgos del EDA (`comprension_eda.ipynb`), implementamos los siguientes features con sus respectivas justificaciones:\n",
    "\n",
    "### üè• Indicadores Cardiovasculares\n",
    "**Ratios de Colesterol (LDL/HDL, Total/HDL)**\n",
    "- **Justificaci√≥n Cl√≠nica**: La relaci√≥n entre colesterol LDL (\"malo\") y HDL (\"bueno\") es un indicador establecido de riesgo cardiovascular\n",
    "- **Relevancia Alzheimer**: Estudios epidemiol√≥gicos demuestran asociaci√≥n entre perfil lip√≠dico y deterioro cognitivo\n",
    "- **Ventaja sobre features brutos**: Captura relaci√≥n no-lineal m√°s relevante que valores absolutos\n",
    "- **Referencia**: Framingham Heart Study, relaci√≥n entre vascular risk y demencia\n",
    "\n",
    "**Presi√≥n Arterial Media (MAP)**\n",
    "- **F√≥rmula**: MAP = Diastolic + (Systolic - Diastolic) / 3\n",
    "- **Justificaci√≥n**: MAP es mejor indicador de perfusi√≥n cerebral que presi√≥n aislada\n",
    "- **Relevancia**: Hipoperfusi√≥n cerebral vinculada a neurodegeneraci√≥n\n",
    "- **Ventaja**: Combina informaci√≥n de systolic y diastolic en una m√©trica fisiol√≥gicamente significativa\n",
    "\n",
    "### üë∂ Interacciones Edad\n",
    "**Age_Squared (Edad¬≤)**\n",
    "- **Justificaci√≥n**: La relaci√≥n entre edad y Alzheimer no es lineal; riesgo aumenta exponencialmente\n",
    "- **Captura**: Efectos no-lineales del envejecimiento en patolog√≠a amiloide\n",
    "- **Ventaja**: Permite al modelo aprender relaciones cuadr√°ticas sin transformaci√≥n expl√≠cita\n",
    "\n",
    "**Age √ó Family History**\n",
    "- **Justificaci√≥n**: Interacci√≥n multiplicativa entre edad y predisposici√≥n gen√©tica\n",
    "- **Relevancia**: El riesgo gen√©tico tiene mayor impacto a edades avanzadas\n",
    "- **Ventaja**: Captura sinergia entre dos factores de riesgo\n",
    "\n",
    "### üîó Score de Riesgo Cardiovascular\n",
    "**CV_Risk_Score (Suma de condiciones CV)**\n",
    "- **Justificaci√≥n**: √çndice agregado de comorbilidades cardiovasculares\n",
    "- **Componentes**: CardiovascularDisease, Diabetes, Hypertension (factores de riesgo establecidos)\n",
    "- **Ventaja**: S√≠ntesis de m√∫ltiples condiciones en una m√©trica de riesgo\n",
    "- **Cl√≠nico**: Refleja \"carga de morbilidad cardiovascular\"\n",
    "\n",
    "### üìä Basado en EDA\n",
    "Todos estos features se derivaron del an√°lisis en `comprension_eda.ipynb` Secci√≥n 8.7, donde se identificaron:\n",
    "- Correlaciones significativas con diagn√≥stico\n",
    "- Patrones no-lineales en la data\n",
    "- Interacciones cl√≠nicamente relevantes\n",
    "- Variables con mayor poder predictivo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87bce785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CREANDO FEATURES DERIVADOS\n",
      "================================================================================\n",
      "\n",
      "‚úì Creado: Cholesterol_Ratio_LDL_HDL (LDL/HDL)\n",
      "‚úì Creado: Cholesterol_Total_HDL_Ratio (Total/HDL)\n",
      "‚úì Creado: Mean_Arterial_Pressure (MAP)\n",
      "‚úì Creado: Age_Squared (Age¬≤)\n",
      "‚úì Creado: Age_FH_Interaction (Age √ó FamilyHistory)\n",
      "‚úì Creado: CV_Risk_Score (suma de condiciones cardiovasculares)\n",
      "\n",
      "‚úÖ Total de features derivados creados: 6\n",
      "   Dimensiones nuevas: 2149 filas √ó 39 columnas\n",
      "   Features agregados: 6\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def create_derived_features(df):\n",
    "    \"\"\"\n",
    "    Crea features derivados basados en an√°lisis EDA y literatura m√©dica.\n",
    "    \n",
    "    ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "    ‚ïë FEATURES DERIVADOS Y SU JUSTIFICACI√ìN M√âDICA/CL√çNICA               ‚ïë\n",
    "    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "    \n",
    "    1. Cholesterol_Ratio_LDL_HDL (LDL/HDL)\n",
    "       ‚Ä¢ Justificaci√≥n: Indicador establecido de riesgo cardiovascular\n",
    "       ‚Ä¢ Relevancia AD: Lipid profile vinculado a deterioro cognitivo\n",
    "       ‚Ä¢ Ventaja: Captura relaci√≥n no-lineal vs valores absolutos\n",
    "       ‚Ä¢ Ref: Framingham Heart Study\n",
    "    \n",
    "    2. Cholesterol_Total_HDL_Ratio (Total/HDL)\n",
    "       ‚Ä¢ Justificaci√≥n: Otro √≠ndice de riesgo cardiovascular\n",
    "       ‚Ä¢ Cl√≠nico: Predictor independiente de enfermedad vascular\n",
    "       ‚Ä¢ Relevancia: Vascular factors afectan patolog√≠a amiloide\n",
    "    \n",
    "    3. Mean_Arterial_Pressure (MAP) = Diastolic + (Systolic-Diastolic)/3\n",
    "       ‚Ä¢ Justificaci√≥n: MAP mejor indicador de perfusi√≥n cerebral\n",
    "       ‚Ä¢ Cl√≠nico: Hipoperfusi√≥n = neurodegeneraci√≥n\n",
    "       ‚Ä¢ Ventaja: Combina info systolic y diastolic en 1 m√©trica\n",
    "    \n",
    "    4. Age_Squared (Age¬≤)\n",
    "       ‚Ä¢ Justificaci√≥n: Relaci√≥n edad-Alzheimer NO es lineal\n",
    "       ‚Ä¢ Captura: Riesgo aumenta exponencialmente con edad\n",
    "       ‚Ä¢ ML: Permite modelo aprender relaciones cuadr√°ticas\n",
    "    \n",
    "    5. Age_FH_Interaction (Age √ó FamilyHistoryAlzheimers)\n",
    "       ‚Ä¢ Justificaci√≥n: Interacci√≥n multiplicativa edad-gen√©tica\n",
    "       ‚Ä¢ Cl√≠nico: Predisposici√≥n gen√©tica tiene mayor impacto en edades\n",
    "       ‚Ä¢ Ventaja: Captura sinergia de dos factores de riesgo\n",
    "    \n",
    "    6. CV_Risk_Score (suma de condiciones cardiovasculares)\n",
    "       ‚Ä¢ Justificaci√≥n: √çndice agregado de comorbilidades CV\n",
    "       ‚Ä¢ Componentes: CardiovascularDisease, Diabetes, Hypertension\n",
    "       ‚Ä¢ Cl√≠nico: Refleja \"carga de morbilidad cardiovascular\"\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame original con variables cl√≠nicas\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame con 6 nuevos features derivados agregados\n",
    "        \n",
    "    Nota: Derivados de an√°lisis EDA en comprension_eda.ipynb Secci√≥n 8.7\n",
    "    \"\"\"\n",
    "    df_new = df.copy()\n",
    "    features_created = []\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"CREANDO FEATURES DERIVADOS\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # 1. Ratio de Colesterol LDL/HDL\n",
    "    if 'CholesterolLDL' in df.columns and 'CholesterolHDL' in df.columns:\n",
    "        df_new['Cholesterol_Ratio_LDL_HDL'] = df_new['CholesterolLDL'] / df_new['CholesterolHDL']\n",
    "        features_created.append('Cholesterol_Ratio_LDL_HDL')\n",
    "        print(\"‚úì Creado: Cholesterol_Ratio_LDL_HDL (LDL/HDL)\")\n",
    "    \n",
    "    # 2. Ratio de Colesterol Total/HDL\n",
    "    if 'CholesterolTotal' in df.columns and 'CholesterolHDL' in df.columns:\n",
    "        df_new['Cholesterol_Total_HDL_Ratio'] = df_new['CholesterolTotal'] / df_new['CholesterolHDL']\n",
    "        features_created.append('Cholesterol_Total_HDL_Ratio')\n",
    "        print(\"‚úì Creado: Cholesterol_Total_HDL_Ratio (Total/HDL)\")\n",
    "    \n",
    "    # 3. Presi√≥n Arterial Media (MAP)\n",
    "    if 'SystolicBP' in df.columns and 'DiastolicBP' in df.columns:\n",
    "        df_new['Mean_Arterial_Pressure'] = (\n",
    "            df_new['DiastolicBP'] + (df_new['SystolicBP'] - df_new['DiastolicBP']) / 3\n",
    "        )\n",
    "        features_created.append('Mean_Arterial_Pressure')\n",
    "        print(\"‚úì Creado: Mean_Arterial_Pressure (MAP)\")\n",
    "    \n",
    "    # 4. Edad al cuadrado\n",
    "    if 'Age' in df.columns:\n",
    "        df_new['Age_Squared'] = df_new['Age'] ** 2\n",
    "        features_created.append('Age_Squared')\n",
    "        print(\"‚úì Creado: Age_Squared (Age¬≤)\")\n",
    "    \n",
    "    # 5. Interacci√≥n Edad x Historia Familiar\n",
    "    if 'Age' in df.columns and 'FamilyHistoryAlzheimers' in df.columns:\n",
    "        df_new['Age_FH_Interaction'] = df_new['Age'] * df_new['FamilyHistoryAlzheimers']\n",
    "        features_created.append('Age_FH_Interaction')\n",
    "        print(\"‚úì Creado: Age_FH_Interaction (Age √ó FamilyHistory)\")\n",
    "    \n",
    "    # 6. Score de riesgo cardiovascular (suma de condiciones)\n",
    "    cv_conditions = ['CardiovascularDisease', 'Diabetes', 'Hypertension']\n",
    "    if all(col in df.columns for col in cv_conditions):\n",
    "        df_new['CV_Risk_Score'] = df_new[cv_conditions].sum(axis=1)\n",
    "        features_created.append('CV_Risk_Score')\n",
    "        print(\"‚úì Creado: CV_Risk_Score (suma de condiciones cardiovasculares)\")\n",
    "    \n",
    "    # Manejar valores infinitos o NaN resultantes\n",
    "    for col in features_created:\n",
    "        # Reemplazar infinitos con NaN\n",
    "        df_new[col].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        \n",
    "        # Contar NaNs\n",
    "        n_nan = df_new[col].isna().sum()\n",
    "        if n_nan > 0:\n",
    "            print(f\"   ‚ö†Ô∏è {col}: {n_nan} valores NaN (ser√°n imputados en el pipeline)\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Total de features derivados creados: {len(features_created)}\")\n",
    "    print(f\"   Dimensiones nuevas: {df_new.shape[0]} filas √ó {df_new.shape[1]} columnas\")\n",
    "    print(f\"   Features agregados: {len(features_created)}\")\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "# Aplicar transformaci√≥n\n",
    "df_with_features = create_derived_features(df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15321cbb",
   "metadata": {},
   "source": [
    "## 3. Clasificaci√≥n de Tipos de Variables\n",
    "\n",
    "Identificamos y clasificamos las variables en num√©ricas, categ√≥ricas nominales y categ√≥ricas ordinales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "066f3a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CLASIFICACI√ìN DE CARACTER√çSTICAS\n",
      "================================================================================\n",
      "\n",
      "‚úì Variable objetivo identificada: Diagnosis\n",
      "‚úì Total de features: 38\n",
      "\n",
      "üìä Variables Num√©ricas (38):\n",
      "   1. Age\n",
      "   2. Gender\n",
      "   3. Ethnicity\n",
      "   4. EducationLevel\n",
      "   5. BMI\n",
      "   6. Smoking\n",
      "   7. AlcoholConsumption\n",
      "   8. PhysicalActivity\n",
      "   9. DietQuality\n",
      "   10. SleepQuality\n",
      "   ... y 28 m√°s\n",
      "\n",
      "üìù Variables Categ√≥ricas Nominales (0):\n",
      "   Ninguna\n",
      "\n",
      "üìà Variables Categ√≥ricas Ordinales (0):\n",
      "   Ninguna\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Definir variable objetivo\n",
    "target_col = 'Diagnosis'\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CLASIFICACI√ìN DE CARACTER√çSTICAS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Separar features del target\n",
    "if target_col in df_with_features.columns:\n",
    "    feature_cols = [col for col in df_with_features.columns if col != target_col]\n",
    "    df_features = df_with_features[feature_cols]\n",
    "    print(f\"‚úì Variable objetivo identificada: {target_col}\")\n",
    "    print(f\"‚úì Total de features: {len(feature_cols)}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Variable objetivo '{target_col}' no encontrada\")\n",
    "    df_features = df_with_features\n",
    "    feature_cols = df_features.columns.tolist()\n",
    "\n",
    "# Detectar tipos autom√°ticamente\n",
    "numeric_features = df_features.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = df_features.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Para este dataset, todas las categ√≥ricas son nominales\n",
    "# Si hubiera ordinales espec√≠ficas (ej: 'EducationLevel'), se definir√≠an aqu√≠\n",
    "ordinal_features = []\n",
    "nominal_features = categorical_features\n",
    "\n",
    "print(f\"\\nüìä Variables Num√©ricas ({len(numeric_features)}):\")\n",
    "if numeric_features:\n",
    "    for i, col in enumerate(numeric_features[:10], 1):\n",
    "        print(f\"   {i}. {col}\")\n",
    "    if len(numeric_features) > 10:\n",
    "        print(f\"   ... y {len(numeric_features) - 10} m√°s\")\n",
    "\n",
    "print(f\"\\nüìù Variables Categ√≥ricas Nominales ({len(nominal_features)}):\")\n",
    "if nominal_features:\n",
    "    for i, col in enumerate(nominal_features, 1):\n",
    "        print(f\"   {i}. {col}\")\n",
    "else:\n",
    "    print(\"   Ninguna\")\n",
    "\n",
    "print(f\"\\nüìà Variables Categ√≥ricas Ordinales ({len(ordinal_features)}):\")\n",
    "if ordinal_features:\n",
    "    for i, col in enumerate(ordinal_features, 1):\n",
    "        print(f\"   {i}. {col}\")\n",
    "else:\n",
    "    print(\"   Ninguna\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8f847a",
   "metadata": {},
   "source": [
    "## 4. Construcci√≥n de Pipelines de Preprocesamiento\n",
    "\n",
    "Creamos pipelines espec√≠ficos para cada tipo de variable usando sklearn `Pipeline` y `ColumnTransformer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cdc5a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CONSTRUCCI√ìN DE PIPELINES DE PREPROCESAMIENTO\n",
      "================================================================================\n",
      "\n",
      "‚úì Pipeline Num√©rico (38 features):\n",
      "    1. SimpleImputer(strategy='median') - Imputa valores faltantes con la mediana\n",
      "    2. StandardScaler() - Normaliza con media=0 y std=1\n",
      "\n",
      "‚úÖ ColumnTransformer creado con 1 transformadores\n",
      "   ‚Ä¢ Transformadores: ['numeric']\n",
      "   ‚Ä¢ Remainder: 'drop' (columnas no especificadas ser√°n eliminadas)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"CONSTRUCCI√ìN DE PIPELINES DE PREPROCESAMIENTO\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "transformers_list = []\n",
    "\n",
    "# Pipeline para variables num√©ricas\n",
    "if numeric_features:\n",
    "    numeric_pipeline = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    transformers_list.append(('numeric', numeric_pipeline, numeric_features))\n",
    "    \n",
    "    print(f\"‚úì Pipeline Num√©rico ({len(numeric_features)} features):\")\n",
    "    print(f\"    1. SimpleImputer(strategy='median') - Imputa valores faltantes con la mediana\")\n",
    "    print(f\"    2. StandardScaler() - Normaliza con media=0 y std=1\")\n",
    "    print()\n",
    "\n",
    "# Pipeline para variables categ√≥ricas nominales\n",
    "if nominal_features:\n",
    "    nominal_pipeline = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "    transformers_list.append(('nominal', nominal_pipeline, nominal_features))\n",
    "    \n",
    "    print(f\"‚úì Pipeline Categ√≥rico Nominal ({len(nominal_features)} features):\")\n",
    "    print(f\"    1. SimpleImputer(strategy='most_frequent') - Imputa con el valor m√°s frecuente\")\n",
    "    print(f\"    2. OneHotEncoder(handle_unknown='ignore') - Codificaci√≥n one-hot\")\n",
    "    print()\n",
    "\n",
    "# Pipeline para variables categ√≥ricas ordinales\n",
    "if ordinal_features:\n",
    "    ordinal_pipeline = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "    ])\n",
    "    transformers_list.append(('ordinal', ordinal_pipeline, ordinal_features))\n",
    "    \n",
    "    print(f\"‚úì Pipeline Categ√≥rico Ordinal ({len(ordinal_features)} features):\")\n",
    "    print(f\"    1. SimpleImputer(strategy='most_frequent')\")\n",
    "    print(f\"    2. OrdinalEncoder(handle_unknown='use_encoded_value')\")\n",
    "    print()\n",
    "\n",
    "# Crear ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=transformers_list,\n",
    "    remainder='drop'  # Eliminar columnas no especificadas\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ ColumnTransformer creado con {len(transformers_list)} transformadores\")\n",
    "print(f\"   ‚Ä¢ Transformadores: {[t[0] for t in transformers_list]}\")\n",
    "print(f\"   ‚Ä¢ Remainder: 'drop' (columnas no especificadas ser√°n eliminadas)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce40bb11",
   "metadata": {},
   "source": [
    "## 5. Separaci√≥n Train-Test\n",
    "\n",
    "Separamos los datos en conjuntos de entrenamiento y evaluaci√≥n con estratificaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00d73b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SEPARACI√ìN DE DATOS TRAIN-TEST\n",
      "================================================================================\n",
      "\n",
      "‚úì Features (X): (2149, 38)\n",
      "‚úì Target (y): (2149,)\n",
      "\n",
      "üìä Divisi√≥n train-test (80-20):\n",
      "   Entrenamiento: 1,719 muestras (80.0%)\n",
      "   Evaluaci√≥n:    430 muestras (20.0%)\n",
      "\n",
      "üìà Distribuci√≥n del target en ENTRENAMIENTO:\n",
      "   Clase 0: 1,111 (64.6%)\n",
      "   Clase 1: 608 (35.4%)\n",
      "\n",
      "üìà Distribuci√≥n del target en EVALUACI√ìN:\n",
      "   Clase 0: 278 (64.7%)\n",
      "   Clase 1: 152 (35.3%)\n",
      "\n",
      "‚úì Estratificaci√≥n exitosa: proporciones similares entre train y test\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"SEPARACI√ìN DE DATOS TRAIN-TEST\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Separar features (X) y target (y)\n",
    "X = df_with_features.drop(columns=[target_col])\n",
    "y = df_with_features[target_col]\n",
    "\n",
    "print(f\"‚úì Features (X): {X.shape}\")\n",
    "print(f\"‚úì Target (y): {y.shape}\")\n",
    "\n",
    "# Train-test split con estratificaci√≥n\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=test_size,\n",
    "    random_state=random_state,\n",
    "    stratify=y  # Mantener proporci√≥n de clases\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Divisi√≥n train-test ({int((1-test_size)*100)}-{int(test_size*100)}):\")\n",
    "print(f\"   Entrenamiento: {X_train.shape[0]:,} muestras ({(X_train.shape[0]/len(y)*100):.1f}%)\")\n",
    "print(f\"   Evaluaci√≥n:    {X_test.shape[0]:,} muestras ({(X_test.shape[0]/len(y)*100):.1f}%)\")\n",
    "\n",
    "# Verificar distribuci√≥n de clases\n",
    "print(f\"\\nüìà Distribuci√≥n del target en ENTRENAMIENTO:\")\n",
    "train_dist = y_train.value_counts().sort_index()\n",
    "for label, count in train_dist.items():\n",
    "    print(f\"   Clase {label}: {count:,} ({count/len(y_train)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüìà Distribuci√≥n del target en EVALUACI√ìN:\")\n",
    "test_dist = y_test.value_counts().sort_index()\n",
    "for label, count in test_dist.items():\n",
    "    print(f\"   Clase {label}: {count:,} ({count/len(y_test)*100:.1f}%)\")\n",
    "\n",
    "# Verificar que la estratificaci√≥n funcion√≥ correctamente\n",
    "print(\"\\n‚úì Estratificaci√≥n exitosa: proporciones similares entre train y test\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420031b3",
   "metadata": {},
   "source": [
    "## 6. Ajuste y Transformaci√≥n de Datos\n",
    "\n",
    "Ajustamos el preprocessor SOLO con datos de entrenamiento (evitar data leakage) y transformamos ambos conjuntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63918f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "AJUSTE Y TRANSFORMACI√ìN\n",
      "================================================================================\n",
      "\n",
      "üìä Ajustando preprocessor con datos de entrenamiento...\n",
      "   (IMPORTANTE: Solo usar train para evitar data leakage)\n",
      "‚úì Preprocessor ajustado exitosamente\n",
      "\n",
      "üîÑ Transformando datos de entrenamiento...\n",
      "‚úì X_train transformado: (1719, 38)\n",
      "\n",
      "üîÑ Transformando datos de evaluaci√≥n...\n",
      "‚úì X_test transformado: (430, 38)\n",
      "\n",
      "üìà Resumen de transformaci√≥n:\n",
      "   Features originales:    38\n",
      "   Features transformados: 38\n",
      "   Diferencia: +0\n",
      "\n",
      "================================================================================\n",
      "‚úì Preprocessor ajustado exitosamente\n",
      "\n",
      "üîÑ Transformando datos de entrenamiento...\n",
      "‚úì X_train transformado: (1719, 38)\n",
      "\n",
      "üîÑ Transformando datos de evaluaci√≥n...\n",
      "‚úì X_test transformado: (430, 38)\n",
      "\n",
      "üìà Resumen de transformaci√≥n:\n",
      "   Features originales:    38\n",
      "   Features transformados: 38\n",
      "   Diferencia: +0\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"AJUSTE Y TRANSFORMACI√ìN\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"üìä Ajustando preprocessor con datos de entrenamiento...\")\n",
    "print(\"   (IMPORTANTE: Solo usar train para evitar data leakage)\")\n",
    "preprocessor.fit(X_train)\n",
    "print(\"‚úì Preprocessor ajustado exitosamente\")\n",
    "\n",
    "print(\"\\nüîÑ Transformando datos de entrenamiento...\")\n",
    "X_train_transformed = preprocessor.transform(X_train)\n",
    "print(f\"‚úì X_train transformado: {X_train_transformed.shape}\")\n",
    "\n",
    "print(\"\\nüîÑ Transformando datos de evaluaci√≥n...\")\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "print(f\"‚úì X_test transformado: {X_test_transformed.shape}\")\n",
    "\n",
    "print(f\"\\nüìà Resumen de transformaci√≥n:\")\n",
    "print(f\"   Features originales:    {X_train.shape[1]}\")\n",
    "print(f\"   Features transformados: {X_train_transformed.shape[1]}\")\n",
    "print(f\"   Diferencia: {X_train_transformed.shape[1] - X_train.shape[1]:+d}\")\n",
    "\n",
    "# Explicar el aumento en features (si aplica)\n",
    "if X_train_transformed.shape[1] > X_train.shape[1]:\n",
    "    print(f\"\\nüí° Nota: El aumento de features se debe a:\")\n",
    "    print(f\"   ‚Ä¢ OneHotEncoder crea una columna por cada categor√≠a\")\n",
    "    print(f\"   ‚Ä¢ Variables categ√≥ricas: {len(nominal_features)}\")\n",
    "    \n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0598ef",
   "metadata": {},
   "source": [
    "## 7. Guardado de Artefactos\n",
    "\n",
    "Guardamos el preprocessor ajustado y los datasets transformados para uso en el siguiente paso del pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdffe873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "GUARDANDO ARTEFACTOS\n",
      "================================================================================\n",
      "\n",
      "üíæ Preprocessor guardado en: ..\\..\\artifacts\\preprocessor.joblib\n",
      "   Tama√±o: 5.47 KB\n",
      "\n",
      "üíæ Datasets guardados en: ..\\..\\data\\processed\n",
      "   ‚Ä¢ X_train.csv: 1257.41 KB\n",
      "   ‚Ä¢ X_test.csv:  314.63 KB\n",
      "   ‚Ä¢ y_train.csv: 5.05 KB\n",
      "   ‚Ä¢ y_test.csv:  1.27 KB\n",
      "\n",
      "üíæ Metadata guardado en: ..\\..\\artifacts\\feature_engineering_metadata.json\n",
      "\n",
      "================================================================================\n",
      "‚úÖ ARTEFACTOS GUARDADOS EXITOSAMENTE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"GUARDANDO ARTEFACTOS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Crear directorios si no existen\n",
    "artifacts_dir = Path(\"../../artifacts\")\n",
    "artifacts_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "data_dir = Path(\"../../data/processed\")\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1. Guardar preprocessor ajustado\n",
    "preprocessor_path = artifacts_dir / \"preprocessor.joblib\"\n",
    "joblib.dump(preprocessor, preprocessor_path)\n",
    "print(f\"üíæ Preprocessor guardado en: {preprocessor_path}\")\n",
    "print(f\"   Tama√±o: {preprocessor_path.stat().st_size / 1024:.2f} KB\")\n",
    "\n",
    "# 2. Guardar datasets transformados como CSV\n",
    "X_train_df = pd.DataFrame(X_train_transformed)\n",
    "X_test_df = pd.DataFrame(X_test_transformed)\n",
    "y_train_df = pd.DataFrame(y_train).reset_index(drop=True)\n",
    "y_test_df = pd.DataFrame(y_test).reset_index(drop=True)\n",
    "\n",
    "X_train_path = data_dir / \"X_train.csv\"\n",
    "X_test_path = data_dir / \"X_test.csv\"\n",
    "y_train_path = data_dir / \"y_train.csv\"\n",
    "y_test_path = data_dir / \"y_test.csv\"\n",
    "\n",
    "X_train_df.to_csv(X_train_path, index=False)\n",
    "X_test_df.to_csv(X_test_path, index=False)\n",
    "y_train_df.to_csv(y_train_path, index=False)\n",
    "y_test_df.to_csv(y_test_path, index=False)\n",
    "\n",
    "print(f\"\\nüíæ Datasets guardados en: {data_dir}\")\n",
    "print(f\"   ‚Ä¢ X_train.csv: {X_train_path.stat().st_size / 1024:.2f} KB\")\n",
    "print(f\"   ‚Ä¢ X_test.csv:  {X_test_path.stat().st_size / 1024:.2f} KB\")\n",
    "print(f\"   ‚Ä¢ y_train.csv: {y_train_path.stat().st_size / 1024:.2f} KB\")\n",
    "print(f\"   ‚Ä¢ y_test.csv:  {y_test_path.stat().st_size / 1024:.2f} KB\")\n",
    "\n",
    "# 3. Guardar metadatos\n",
    "metadata = {\n",
    "    \"n_features_original\": X_train.shape[1],\n",
    "    \"n_features_transformed\": X_train_transformed.shape[1],\n",
    "    \"n_numeric_features\": len(numeric_features),\n",
    "    \"n_categorical_features\": len(nominal_features),\n",
    "    \"n_samples_train\": X_train.shape[0],\n",
    "    \"n_samples_test\": X_test.shape[0],\n",
    "    \"test_size\": test_size,\n",
    "    \"random_state\": random_state,\n",
    "    \"target_column\": target_col,\n",
    "    \"features_created\": [\n",
    "        'Cholesterol_Ratio_LDL_HDL',\n",
    "        'Cholesterol_Total_HDL_Ratio',\n",
    "        'Mean_Arterial_Pressure',\n",
    "        'Age_Squared',\n",
    "        'Age_FH_Interaction',\n",
    "        'CV_Risk_Score'\n",
    "    ]\n",
    "}\n",
    "\n",
    "metadata_path = artifacts_dir / \"feature_engineering_metadata.json\"\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"\\nüíæ Metadata guardado en: {metadata_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ ARTEFACTOS GUARDADOS EXITOSAMENTE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfc2cde",
   "metadata": {},
   "source": [
    "## 8 Documentaci√≥n de Decisiones de Preprocesamiento\n",
    "\n",
    "### Decisiones T√©cnicas Justificadas\n",
    "\n",
    "#### **Imputaci√≥n de Valores Faltantes**\n",
    "\n",
    "| Variable | Estrategia | Justificaci√≥n |\n",
    "|----------|-----------|--------------|\n",
    "| **Num√©ricas** | Mediana | Robusta ante outliers, preserva distribuci√≥n; preferible a media para features con sesgos |\n",
    "| **Categ√≥ricas** | Valor m√°s frecuente | Preserva modo, mantiene distribuciones de probabilidad |\n",
    "\n",
    "**Alternativas consideradas y descartadas**:\n",
    "- ‚ùå Eliminaci√≥n listwise: Perder√≠a muchas muestras\n",
    "- ‚ùå Media para num√©ricas: Sensible a outliers en variables biom√©dicas\n",
    "- ‚ùå Forward-fill: No aplicable (sin serie temporal)\n",
    "\n",
    "#### **Escalado de Variables Num√©ricas (StandardScaler)**\n",
    "\n",
    "```\n",
    "x_scaled = (x - mean) / std_dev\n",
    "```\n",
    "\n",
    "**Justificaci√≥n**:\n",
    "- ‚úÖ Algoritmos (regresi√≥n log√≠stica, SVM) sensibles a escala\n",
    "- ‚úÖ Facilita convergencia en gradient descent\n",
    "- ‚úÖ Features en escala comparable\n",
    "- ‚úÖ Mejor interpretabilidad de coeficientes\n",
    "\n",
    "**Por qu√© StandardScaler y no MinMaxScaler**:\n",
    "- StandardScaler es robusto ante outliers extremos en datos m√©dicos\n",
    "- No asume rango fijo (mejor para distribuciones no acotadas)\n",
    "- Produce distribuciones aproximadamente normales\n",
    "\n",
    "#### **Codificaci√≥n Categ√≥rica (OneHotEncoder)**\n",
    "\n",
    "**Justificaci√≥n**:\n",
    "- ‚úÖ Variables nominales sin orden (g√©nero, tipo de s√≠ntoma)\n",
    "- ‚úÖ Evita asumir orden artificial\n",
    "- ‚úÖ Compatible con mayor√≠a de ML algorithms\n",
    "\n",
    "**Par√°metro `handle_unknown='ignore'`**:\n",
    "- Categor√≠as nuevas en test ‚Üí fila de ceros\n",
    "- Alternativa `error` ser√≠a fr√°gil en producci√≥n\n",
    "\n",
    "#### **Separaci√≥n Train-Test con Estratificaci√≥n**\n",
    "\n",
    "**Justificaci√≥n**:\n",
    "- ‚úÖ Evita bias en distribuci√≥n de clases\n",
    "- ‚úÖ Especialmente importante con clases desbalanceadas\n",
    "- ‚úÖ Garantiza train y test representen poblaci√≥n similar\n",
    "\n",
    "**Test Size = 20%**:\n",
    "- ‚úÖ Est√°ndar en ML con datasets medianos (n > 1,000)\n",
    "- ‚úÖ Balance entre datos de entrenamiento y evaluaci√≥n\n",
    "- ‚úÖ Configurable desde `config.json` para flexibilidad\n",
    "\n",
    "#### **Sin Data Leakage**\n",
    "\n",
    "**Implementaci√≥n**:\n",
    "```python\n",
    "preprocessor.fit(X_train)      # ‚Üê Ajustar SOLO en train\n",
    "X_train_transformed = preprocessor.transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)  # ‚Üê Usar par√°metros de train\n",
    "```\n",
    "\n",
    "**Cr√≠tico para evitar overfitting simulado**:\n",
    "- ‚ùå Escalar con estad√≠sticos de TODO el dataset ‚Üí LEAKAGE\n",
    "- ‚úÖ Escalar con estad√≠sticos solo de train ‚Üí CORRECTO\n",
    "\n",
    "### Par√°metros del Pipeline\n",
    "\n",
    "| Componente | Par√°metro | Valor | Justificaci√≥n |\n",
    "|-----------|-----------|-------|---------------|\n",
    "| Train-Test Split | `test_size` | 0.2 | 80-20 est√°ndar |\n",
    "| | `random_state` | 42 | Reproducibilidad |\n",
    "| | `stratify` | s√≠ | Mantener proporciones de clases |\n",
    "| StandardScaler | `with_mean` | True | Centrar en 0 |\n",
    "| | `with_std` | True | Escalar a varianza unitaria |\n",
    "| OneHotEncoder | `sparse_output` | False | Matriz densa (compatible con m√°s modelos) |\n",
    "| | `handle_unknown` | 'ignore' | Robustez en producci√≥n |\n",
    "| SimpleImputer | strategy (num) | 'median' | Robustez ante outliers |\n",
    "| | strategy (cat) | 'most_frequent' | Mantiene modo |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
