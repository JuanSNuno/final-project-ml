# ğŸš€ Pipeline MLOps - Alzheimer's Disease Prediction

Pipeline completo de MLOps para predicciÃ³n de Alzheimer usando Machine Learning.

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa un pipeline end-to-end de MLOps que incluye:
- âœ… Procesamiento y limpieza de datos
- âœ… Feature Engineering con ColumnTransformer
- âœ… Entrenamiento y evaluaciÃ³n de mÃºltiples modelos
- âœ… Despliegue como API REST con FastAPI
- âœ… Monitoreo de Data Drift (PSI, KS test, Chi-cuadrado)
- âœ… Dashboard de visualizaciÃ³n con Streamlit
- âœ… ContainerizaciÃ³n con Docker

## ğŸ—ï¸ Estructura del Proyecto

```
final-project-ml/
â”œâ”€â”€ mlops_pipeline/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ data_processing.py              # Paso 1: Carga y limpieza de datos
â”‚       â”œâ”€â”€ ft_engineering.py               # Paso 2: Feature Engineering
â”‚       â”œâ”€â”€ model_training_evaluation.py    # Paso 3: Entrenamiento y evaluaciÃ³n
â”‚       â”œâ”€â”€ model_deploy.py                 # Paso 4: API de despliegue
â”‚       â”œâ”€â”€ model_monitoring.py             # Paso 5: Monitoreo de drift
â”‚       â””â”€â”€ streamlit_app.py                # Dashboard de visualizaciÃ³n
â”œâ”€â”€ data/
â”‚   â””â”€â”€ processed/                          # Datasets procesados
â”œâ”€â”€ artifacts/                              # Modelos y transformadores
â”œâ”€â”€ monitoring_results/                     # Reportes de monitoreo
â”œâ”€â”€ run_pipeline.py                         # Script maestro del pipeline
â”œâ”€â”€ Dockerfile                              # ConfiguraciÃ³n de Docker
â”œâ”€â”€ requirements.txt                        # Dependencias
â””â”€â”€ config.json                             # ConfiguraciÃ³n del proyecto
```

## ğŸ”§ InstalaciÃ³n

### Requisitos Previos
- Python 3.10+
- pip

### Instalar Dependencias

```powershell
pip install -r requirements.txt
```

## ğŸš€ Uso

### OpciÃ³n 1: Ejecutar Pipeline Completo (Recomendado)

```powershell
# Pipeline bÃ¡sico (pasos 1-4)
python run_pipeline.py

# Pipeline completo con despliegue y visualizaciÃ³n
python run_pipeline.py --full

# Solo pipeline con API
python run_pipeline.py --deploy

# Solo pipeline con Streamlit
python run_pipeline.py --streamlit
```

### OpciÃ³n 2: Ejecutar Pasos Individuales

#### Paso 1: Procesamiento de Datos
```powershell
python mlops_pipeline/src/data_processing.py
```
**Output:** `data/processed/cleaned_data.csv`

#### Paso 2: Feature Engineering
```powershell
python mlops_pipeline/src/ft_engineering.py
```
**Output:** 
- `artifacts/preprocessor.joblib`
- `data/processed/X_train.csv`, `X_test.csv`, `y_train.csv`, `y_test.csv`

#### Paso 3: Entrenamiento y EvaluaciÃ³n
```powershell
python mlops_pipeline/src/model_training_evaluation.py
```
**Output:**
- `artifacts/best_model.joblib`
- `artifacts/model_metadata.json`
- `artifacts/model_evaluation_results.csv`

#### Paso 4: Monitoreo de Data Drift
```powershell
python mlops_pipeline/src/model_monitoring.py
```
**Output:**
- `monitoring_results/drift_report.csv`
- `monitoring_results/drift_summary.json`

#### Paso 5: Desplegar API
```powershell
python mlops_pipeline/src/model_deploy.py
```
**Acceso:**
- API: http://localhost:8000
- DocumentaciÃ³n interactiva: http://localhost:8000/docs

#### Paso 6: Dashboard de VisualizaciÃ³n
```powershell
streamlit run mlops_pipeline/src/streamlit_app.py
```

## ğŸ‹ Docker

### Construir Imagen
```powershell
docker build -t alzheimer-api .
```

### Ejecutar Contenedor
```powershell
docker run -p 8000:8000 alzheimer-api
```

### Acceder a la API
- URL: http://localhost:8000
- DocumentaciÃ³n: http://localhost:8000/docs

## ğŸ“Š API Endpoints

### GET /
InformaciÃ³n general de la API

### GET /health
Estado de salud de la API

### GET /model/info
InformaciÃ³n del modelo cargado

### POST /predict
Realizar una predicciÃ³n

**Ejemplo de Request:**
```json
{
  "Age": 75.0,
  "Gender": 1,
  "Ethnicity": 0,
  "EducationLevel": 2,
  "BMI": 25.5,
  "Smoking": 0,
  "AlcoholConsumption": 5.0,
  "PhysicalActivity": 6.5,
  "DietQuality": 7.0,
  "SleepQuality": 7.5,
  "FamilyHistoryAlzheimers": 1,
  ...
}
```

**Respuesta:**
```json
{
  "prediction": 1,
  "probability": 0.87,
  "model_name": "Random Forest"
}
```

### POST /predict/batch
Realizar predicciones en lote

## ğŸ“ˆ Monitoreo de Data Drift

El pipeline implementa tres mÃ©tricas principales de data drift:

1. **PSI (Population Stability Index)**
   - PSI < 0.1: Sin cambio significativo
   - 0.1 â‰¤ PSI < 0.25: Cambio moderado
   - PSI â‰¥ 0.25: Cambio significativo

2. **Test de Kolmogorov-Smirnov (KS)**
   - Mide diferencias en distribuciones acumuladas
   - p-value < 0.05 indica drift significativo

3. **Chi-cuadrado (Variables categÃ³ricas)**
   - Mide cambios en distribuciÃ³n de categorÃ­as
   - Incluye CramÃ©r's V como medida del tamaÃ±o del efecto

## ğŸ“Š Dashboard Streamlit

El dashboard incluye:
- ğŸ“Š Resumen ejecutivo con mÃ©tricas clave
- ğŸ“ˆ VisualizaciÃ³n de distribuciones (baseline vs actual)
- ğŸ“‹ Tabla detallada de mÃ©tricas de drift
- ğŸ’¡ Recomendaciones automatizadas
- ğŸ¨ GrÃ¡ficos interactivos

## ğŸ§ª Modelos Entrenados

El pipeline evalÃºa mÃºltiples algoritmos:
- Logistic Regression
- Random Forest
- Gradient Boosting
- Decision Tree
- K-Nearest Neighbors (KNN)
- Support Vector Machine (SVM)

El mejor modelo se selecciona automÃ¡ticamente basado en:
- F1-Score (mÃ©trica principal)
- Test Accuracy
- Bajo overfitting

## ğŸ“ Artefactos Generados

### `/data/processed/`
- `cleaned_data.csv`: Dataset limpio
- `X_train.csv`, `X_test.csv`: Features transformados
- `y_train.csv`, `y_test.csv`: Target

### `/artifacts/`
- `preprocessor.joblib`: ColumnTransformer ajustado
- `best_model.joblib`: Mejor modelo entrenado
- `model_metadata.json`: Metadata del modelo
- `model_evaluation_results.csv`: Resultados de evaluaciÃ³n

### `/monitoring_results/`
- `drift_report.csv`: Reporte detallado de drift
- `drift_summary.json`: Resumen de drift

## ğŸ”§ ConfiguraciÃ³n

Edita `config.json` para ajustar parÃ¡metros:

```json
{
  "project": "final-project-ml",
  "data_path": "alzheimers_disease_data.csv",
  "training": {
    "test_size": 0.2,
    "random_state": 42
  }
}
```

## ğŸ› ï¸ Desarrollo

### Estructura de Pipeline

El pipeline sigue un flujo secuencial donde cada paso guarda artefactos que son consumidos por el siguiente:

```
Data Processing â†’ Feature Engineering â†’ Model Training â†’ Model Deployment
                                              â†“
                                         Monitoring â† Streamlit Dashboard
```

### Buenas PrÃ¡cticas Implementadas

- âœ… SeparaciÃ³n de concerns (cada script tiene una responsabilidad Ãºnica)
- âœ… Artefactos versionables (joblib para modelos y transformadores)
- âœ… ConfiguraciÃ³n externalizada (config.json)
- âœ… Logging informativo en cada paso
- âœ… ValidaciÃ³n de datos y manejo de errores
- âœ… CÃ³digo modular y reutilizable
- âœ… DocumentaciÃ³n inline y docstrings

## ğŸ“ Notas

- Los datos deben estar en formato CSV con las columnas esperadas
- El modelo debe ser reentrenado si se detecta drift significativo
- La API carga los artefactos al inicio (preprocessor + modelo)
- Streamlit lee los reportes de monitoreo desde archivos

## ğŸ¤ Contribuciones

Este proyecto es parte de un ejercicio acadÃ©mico de MLOps.

## ğŸ“„ Licencia

Proyecto acadÃ©mico - Universidad

---

**Desarrollado con â¤ï¸ para el curso de Machine Learning**
