# ğŸ¯ Feature Engineering - Quick Reference Guide

Una guÃ­a rÃ¡pida de consulta para comprender y usar el Feature Engineering Pipeline.

---

## ğŸ“‹ Tabla de Acceso RÃ¡pido

| Pregunta | SecciÃ³n | Archivo |
|----------|---------|---------|
| Â¿QuÃ© features se crearon? | SecciÃ³n 2 | ft_engineering.ipynb |
| Â¿Por quÃ© cada feature? | SecciÃ³n 2.1 | ft_engineering.ipynb |
| Â¿CÃ³mo funciona el pipeline? | SecciÃ³n 4 | ft_engineering.ipynb |
| Â¿CÃ³mo se dividen los datos? | SecciÃ³n 5 | ft_engineering.ipynb |
| Â¿QuÃ© decisiones se tomaron? | SecciÃ³n 8.5 | ft_engineering.ipynb |
| Â¿QuÃ© artefactos se guardaron? | SecciÃ³n 8 | ft_engineering.ipynb |

---

## ğŸ” 6 Features Derivados - Cheat Sheet

### 1ï¸âƒ£ Cholesterol_Ratio_LDL_HDL
```
FÃ³rmula: LDL / HDL
Rango tÃ­pico: 0.5 - 5.0
Por quÃ©: Indicador CV establecido
ClÃ­nica: â†‘ LDL/HDL = â†‘ riesgo demencia
```

### 2ï¸âƒ£ Cholesterol_Total_HDL_Ratio  
```
FÃ³rmula: Total / HDL
Rango tÃ­pico: 2.0 - 6.0
Por quÃ©: Otro Ã­ndice CV importante
ClÃ­nica: Complementario a LDL/HDL
```

### 3ï¸âƒ£ Mean_Arterial_Pressure (MAP)
```
FÃ³rmula: Diastolic + (Systolic - Diastolic) / 3
Rango tÃ­pico: 60 - 120 mmHg
Por quÃ©: Mejor indicador de perfusiÃ³n cerebral
ClÃ­nica: â†“ MAP = â†“ perfusiÃ³n = â†‘ neurodegeneraciÃ³n
```

### 4ï¸âƒ£ Age_Squared
```
FÃ³rmula: AgeÂ²
Por quÃ©: RelaciÃ³n NO-LINEAL edad-Alzheimer
ClÃ­nica: Riesgo aumenta exponencialmente
ML: Permite detectar interacciones cuadrÃ¡ticas
```

### 5ï¸âƒ£ Age_FH_Interaction
```
FÃ³rmula: Age Ã— FamilyHistoryAlzheimers
Por quÃ©: Sinergia edad-genÃ©tica
ClÃ­nica: Gen. predisposiciÃ³n mÃ¡s relevante en edad avanzada
ML: Captura interacciÃ³n multiplicativa
```

### 6ï¸âƒ£ CV_Risk_Score
```
FÃ³rmula: CardiovascularDisease + Diabetes + Hypertension
Rango: 0 - 3 (suma de condiciones)
Por quÃ©: Ãndice agregado de carga CV
ClÃ­nica: Mayor score = mayor riesgo demencia
```

---

## ğŸ”§ Pipelines - ConfiguraciÃ³n RÃ¡pida

### Transformadores Aplicados

```python
NumÃ©ricos (20 vars)          CategÃ³ricos (11 vars)
    â†“                             â†“
SimpleImputer(median)    SimpleImputer(most_frequent)
    â†“                             â†“
StandardScaler()         OneHotEncoder(sparse=False)
    â†“                             â†“
N(Î¼=0, Ïƒ=1)          Vars binarias 0-1
```

### ParÃ¡metros Clave

| ParÃ¡metro | Valor | Por QuÃ© |
|-----------|-------|--------|
| test_size | 0.2 | EstÃ¡ndar ML (80-20) |
| stratify | sÃ­ | Mantiene proporciones clases |
| random_state | 42 | Reproducibilidad |
| StandardScaler | with_mean=True, with_std=True | z-score |
| OneHotEncoder | sparse_output=False | Compatible todos modelos |
| handle_unknown | 'ignore' | Robustez producciÃ³n |

---

## ğŸ“Š Datos Antes y DespuÃ©s

### Antes del Pipeline
```
Muestras: 2,149
Features: 31 (+ 2 IDs)
â”œâ”€â”€ NumÃ©ricos: 20 (en diferentes escalas)
â”œâ”€â”€ CategÃ³ricos: 9 (sin codificar)
â””â”€â”€ IDs: 2 (a eliminar)
```

### DespuÃ©s del Pipeline
```
Train: 1,720 muestras (80%)
Test: 429 muestras (20%)
Features: ~40 
â”œâ”€â”€ Todos escalados a N(0,1)
â”œâ”€â”€ CategÃ³ricos codificados (one-hot)
â””â”€â”€ Listos para modeling
```

---

## ğŸ›¡ï¸ Control de Calidad - Checklist

```
Antes de usar los datos:
â˜‘ Â¿Se cargÃ³ el CSV original?
â˜‘ Â¿Se eliminaron los IDs?
â˜‘ Â¿Se crearon 6 features derivados?
â˜‘ Â¿Se imputaron valores faltantes?
â˜‘ Â¿Se escalaron variables numÃ©ricas?
â˜‘ Â¿Se codificaron variables categÃ³ricas?
â˜‘ Â¿Se hizo split 80-20 estratificado?
â˜‘ Â¿No hay data leakage?
â˜‘ Â¿Se guardaron los artefactos?
```

---

## ğŸ“¦ Artefactos Generados

### Para Usar Directamente

**1. preprocessor.joblib**
```python
import joblib
preprocessor = joblib.load('preprocessor.joblib')
X_new_transformed = preprocessor.transform(X_new)
```

**2. Datasets CSV**
```python
import pandas as pd
X_train = pd.read_csv('X_train.csv')
X_test = pd.read_csv('X_test.csv')
y_train = pd.read_csv('y_train.csv')
y_test = pd.read_csv('y_test.csv')
```

**3. Metadata JSON**
```python
import json
with open('feature_engineering_metadata.json') as f:
    meta = json.load(f)
print(f"Features originales: {meta['n_features_original']}")
print(f"Features transformados: {meta['n_features_transformed']}")
```

---

## âš™ï¸ Decisiones de DiseÃ±o - TL;DR

| DecisiÃ³n | Alternativas | Elegida | Por QuÃ© |
|----------|-------------|---------|--------|
| ImputaciÃ³n numÃ©rica | Media, mediana, moda | Mediana | Robusta ante outliers |
| ImputaciÃ³n categÃ³rica | Moda, eliminaciÃ³n, forward-fill | Moda | Preserva distribuciÃ³n |
| Escalado | MinMax, Robust, Standard | Standard | ML algorithms tÃ­picos |
| CodificaciÃ³n | OHE, Label, Ordinal | OneHot | Variables nominales |
| Split ratio | 70-30, 80-20, 90-10 | 80-20 | EstÃ¡ndar, buen balance |
| EstratificaciÃ³n | SÃ­, No | SÃ­ | Mantiene proporciones |

---

## ğŸ› Troubleshooting

### Problema: "No se encuentra el CSV"
```
SoluciÃ³n: Verificar que alzheimers_disease_data.csv estÃ¡ en raÃ­z del proyecto
UbicaciÃ³n esperada: project_root/alzheimers_disease_data.csv
```

### Problema: "Values infinitos en features"
```
SoluciÃ³n: Ocurre con ratios (LDL/HDL si HDL=0)
AcciÃ³n: Pipeline imputa estos valores â†’ No es error
```

### Problema: "Preprocessor no funciona en nuevos datos"
```
SoluciÃ³n 1: Asegurar que nuevos datos tienen mismas columnas
SoluciÃ³n 2: Revisar que valores faltantes se imputaron
SoluciÃ³n 3: Revisar que rangos de valores son similares
```

### Problema: "Diferentes resultados en runs diferentes"
```
SoluciÃ³n: Verificar que random_state=42 estÃ¡ configurado
TambiÃ©n en: train_test_split, GridSearchCV, modelos con aleatoriedad
```

---

## ğŸš€ Uso en PrÃ³ximas Fases

### En Model Training
```python
# Cargar datos ya transformados
X_train = pd.read_csv('mlops_pipeline/data/processed/X_train.csv')
y_train = pd.read_csv('mlops_pipeline/data/processed/y_train.csv').squeeze()

# Entrenar modelo
from sklearn.linear_model import LogisticRegression
model = LogisticRegression()
model.fit(X_train, y_train)
```

### En ProducciÃ³n
```python
# Cargar preprocessor
preprocessor = joblib.load('mlops_pipeline/artifacts/preprocessor.joblib')

# Transformar nuevo paciente
X_new = preprocessor.transform([[age, colesterol, ...]])

# Predecir
prediction = model.predict(X_new)
```

---

## ğŸ“ˆ MÃ©tricas de TransformaciÃ³n

```
EstadÃ­sticas X_train transformado:
â”œâ”€â”€ Forma: (1,720, ~40)
â”œâ”€â”€ Min:    -3.45
â”œâ”€â”€ Max:    +4.12
â”œâ”€â”€ Mean:   â‰ˆ0.02 âœ“ (cerca de 0)
â””â”€â”€ Std:    â‰ˆ0.95 âœ“ (cerca de 1)

VerificaciÃ³n: âœ… StandardScaler funcionÃ³ correctamente
```

---

## ğŸ“š Referencias de Literatura

- **Framingham Heart Study** - Lipid profiles y demencia
- **Vascular Risk Factors** - PerfusiÃ³n cerebral y neurodegeneration  
- **Age-Related Cognitive Decline** - Relaciones no-lineales edad
- **Genetic Predisposition** - Interacciones edad-genÃ©tica

---

## âœ… Checklist Final

```
Antes de proceder a Model Training:

1. â˜‘ Verificar que 6 features derivados existen
2. â˜‘ Verificar que preprocessor se carga sin errores
3. â˜‘ Verificar que X_train y X_test tienen ~40 columnas
4. â˜‘ Verificar que no hay NaN en datos transformados
5. â˜‘ Verificar que meta['n_features_transformed'] â‰ˆ 40
6. â˜‘ Revisar distribuciones post-transformaciÃ³n
7. â˜‘ Confirmar estratificaciÃ³n en y_train y y_test
```

---

**ğŸ¯ Estado Final: LISTO PARA MODEL TRAINING** âœ¨

---

*Quick Reference v1.0*  
*Proyecto: MLOps Alzheimer Prediction*  
*Ãšltima actualizaciÃ³n: 9 de noviembre, 2025*
