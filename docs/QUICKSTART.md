# ğŸ¯ GUÃA RÃPIDA DEL PIPELINE MLOps

## ğŸš€ Inicio RÃ¡pido

### 1ï¸âƒ£ Instalar Dependencias
```powershell
pip install -r requirements.txt
```

### 2ï¸âƒ£ Ejecutar Pipeline Completo
```powershell
python run_pipeline.py
```

## ğŸ“Š Flujo del Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     PIPELINE MLOps SECUENCIAL                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PASO 1: data_processing.py                                   â”‚
    â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” â”‚
    â”‚ INPUT:  alzheimers_disease_data.csv                          â”‚
    â”‚ HACE:   Limpieza y preprocesamiento bÃ¡sico                   â”‚
    â”‚ OUTPUT: data/processed/cleaned_data.csv                      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PASO 2: ft_engineering.py                                    â”‚
    â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” â”‚
    â”‚ INPUT:  data/processed/cleaned_data.csv                      â”‚
    â”‚ HACE:   ColumnTransformer + Train/Test Split                 â”‚
    â”‚ OUTPUT: - artifacts/preprocessor.joblib                      â”‚
    â”‚         - data/processed/X_train.csv, X_test.csv             â”‚
    â”‚         - data/processed/y_train.csv, y_test.csv             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PASO 3: model_training_evaluation.py                         â”‚
    â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” â”‚
    â”‚ INPUT:  data/processed/X_train.csv, y_train.csv              â”‚
    â”‚ HACE:   Entrena 6 modelos y selecciona el mejor             â”‚
    â”‚ OUTPUT: - artifacts/best_model.joblib                        â”‚
    â”‚         - artifacts/model_metadata.json                      â”‚
    â”‚         - artifacts/model_evaluation_results.csv             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PASO 4: model_monitoring.py                                  â”‚
    â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” â”‚
    â”‚ INPUT:  data/processed/cleaned_data.csv (baseline)           â”‚
    â”‚ HACE:   Calcula PSI, KS test, Chi-cuadrado                   â”‚
    â”‚ OUTPUT: - monitoring_results/drift_report.csv                â”‚
    â”‚         - monitoring_results/drift_summary.json              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ DESPLIEGUE: model_deploy.py                                  â”‚
    â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” â”‚
    â”‚ CARGA:  - artifacts/preprocessor.joblib                      â”‚
    â”‚         - artifacts/best_model.joblib                        â”‚
    â”‚ HACE:   API REST con FastAPI                                 â”‚
    â”‚ ACCESO: http://localhost:8000                                â”‚
    â”‚         http://localhost:8000/docs (Swagger)                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ VISUALIZACIÃ“N: streamlit_app.py                              â”‚
    â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” â”‚
    â”‚ LEE:    monitoring_results/*.csv, *.json                     â”‚
    â”‚ HACE:   Dashboard interactivo de monitoreo                   â”‚
    â”‚ ACCESO: http://localhost:8501                                â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¨ Comandos Ãštiles

### Ejecutar Pasos Individuales
```powershell
# Paso 1
python mlops_pipeline/src/data_processing.py

# Paso 2
python mlops_pipeline/src/ft_engineering.py

# Paso 3
python mlops_pipeline/src/model_training_evaluation.py

# Paso 4
python mlops_pipeline/src/model_monitoring.py

# Desplegar API
python mlops_pipeline/src/model_deploy.py

# Streamlit
streamlit run mlops_pipeline/src/streamlit_app.py
```

### Ejecutar con Opciones
```powershell
# Pipeline bÃ¡sico
python run_pipeline.py

# Con API
python run_pipeline.py --deploy

# Con Streamlit
python run_pipeline.py --streamlit

# Todo junto
python run_pipeline.py --full

# Sin entrenamiento (testing)
python run_pipeline.py --skip-training
```

## ğŸ‹ Docker

```powershell
# Construir imagen
docker build -t alzheimer-api .

# Ejecutar contenedor
docker run -p 8000:8000 alzheimer-api

# Acceder
# http://localhost:8000
# http://localhost:8000/docs
```

## ğŸ§ª Probar la API

```powershell
# Iniciar API en una terminal
python mlops_pipeline/src/model_deploy.py

# En otra terminal, ejecutar pruebas
python test_api.py
```

## ğŸ“Š MÃ©tricas de Data Drift

| MÃ©trica | Sin Drift | Moderado | CrÃ­tico |
|---------|-----------|----------|---------|
| PSI     | < 0.1     | 0.1-0.25 | â‰¥ 0.25  |
| KS p-value | â‰¥ 0.05 | < 0.05   | < 0.01  |
| CramÃ©r's V | < 0.1  | 0.1-0.3  | â‰¥ 0.3   |

## ğŸ“ Archivos Clave

| Archivo | DescripciÃ³n |
|---------|-------------|
| `run_pipeline.py` | Script maestro del pipeline |
| `config.json` | ConfiguraciÃ³n del proyecto |
| `Dockerfile` | Imagen Docker de la API |
| `requirements.txt` | Dependencias Python |
| `test_api.py` | Script de pruebas de la API |

## âš ï¸ Notas Importantes

1. **Orden de EjecuciÃ³n**: Los pasos deben ejecutarse en orden (1â†’2â†’3â†’4)
2. **Artefactos**: Cada paso guarda archivos que el siguiente paso necesita
3. **Docker**: Solo incluye la API, no todo el pipeline
4. **Monitoreo**: Streamlit lee archivos generados por model_monitoring.py

## ğŸ†˜ SoluciÃ³n de Problemas

### Error: "No se encontrÃ³ el dataset limpio"
```powershell
# Ejecuta primero el paso 1
python mlops_pipeline/src/data_processing.py
```

### Error: "No se encontrÃ³ preprocessor.joblib"
```powershell
# Ejecuta los pasos 1 y 2
python mlops_pipeline/src/data_processing.py
python mlops_pipeline/src/ft_engineering.py
```

### Error: "No se encontrÃ³ best_model.joblib"
```powershell
# Ejecuta los pasos 1, 2 y 3
python run_pipeline.py
```

### La API no responde
```powershell
# Verifica que estÃ© corriendo
# Debe mostrar: INFO: Uvicorn running on http://0.0.0.0:8000
python mlops_pipeline/src/model_deploy.py
```

## ğŸ“ Estructura de la API

### Endpoints Disponibles

| MÃ©todo | Endpoint | DescripciÃ³n |
|--------|----------|-------------|
| GET | `/` | Info general |
| GET | `/health` | Estado de salud |
| GET | `/model/info` | Info del modelo |
| POST | `/predict` | PredicciÃ³n individual |
| POST | `/predict/batch` | PredicciÃ³n en lote |

---

**Â¡Listo para producciÃ³n! ğŸš€**
